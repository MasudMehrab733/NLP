{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08afec72",
   "metadata": {},
   "source": [
    "#  Natural Language Processing (NLP) Text Preprocessing: A Complete Beginner’s Guide\n",
    "***In the world of Natural Language Processing (NLP), raw text data is often messy and inconsistent. Before applying machine learning models, it's crucial to clean and prepare the text—a process known as text preprocessing. This article will walk you through the most essential preprocessing steps, techniques, and libraries commonly used in NLP.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0205d14a",
   "metadata": {},
   "source": [
    "## 1.This small script takes a sentence and splits it into words (tokens):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "bb58bbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ce02ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text =\"What is NLP? Natural language processing (NLP) is a machine learning technology that gives computers the ability to interpret, manipulate, and comprehend human language. Organizations today have large volumes of voice and text data from various communication channels like emails, text messages, social media newsfeeds, video, audio, and more. They use NLP software to automatically process this data, analyze the intent or sentiment in the message, and respond in real time to human communication.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8ed651ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "token=word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ba054b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['What', 'is', 'NLP', '?', 'Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'machine', 'learning', 'technology', 'that', 'gives', 'computers', 'the', 'ability', 'to', 'interpret', ',', 'manipulate', ',', 'and', 'comprehend', 'human', 'language', '.', 'Organizations', 'today', 'have', 'large', 'volumes', 'of', 'voice', 'and', 'text', 'data', 'from', 'various', 'communication', 'channels', 'like', 'emails', ',', 'text', 'messages', ',', 'social', 'media', 'newsfeeds', ',', 'video', ',', 'audio', ',', 'and', 'more', '.', 'They', 'use', 'NLP', 'software', 'to', 'automatically', 'process', 'this', 'data', ',', 'analyze', 'the', 'intent', 'or', 'sentiment', 'in', 'the', 'message', ',', 'and', 'respond', 'in', 'real', 'time', 'to', 'human', 'communication', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"tokens:\",token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "80d1ff08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f60cbbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "6e76bdfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 9, 'and': 4, 'nlp': 3, 'the': 3, 'to': 3, '.': 3, 'is': 2, 'language': 2, 'human': 2, 'text': 2, ...})"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in token:\n",
    "    fdist[word.lower()]+=1\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "09c5c0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist['nlp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ef0123c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 9), ('and', 4), ('nlp', 3), ('the', 3), ('to', 3)]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_top5 = fdist.most_common(5)\n",
    "fdist_top5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc5eff",
   "metadata": {},
   "source": [
    "## 2. Sentence Tokenization using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "71c94d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 =\"NLP is interesting part in AI. CSE students should try to learn NLP. Many ML models applies in NLP.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1aa12e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tok = sent_tokenize(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "907e8f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentense tokenize ['NLP is interesting part in AI.', 'CSE students should try to learn NLP.', 'Many ML models applies in NLP.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentense tokenize\",sent_tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb487814",
   "metadata": {},
   "source": [
    "##  3. Whitespace Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4abb5f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 =\"Natural language processing is fun & interesting part in computer science and Artificial Inteligence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "755a8c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', 'is', 'fun', '&', 'interesting', 'part', 'in', 'computer', 'science', 'and', 'Artificial', 'Inteligence']\n"
     ]
    }
   ],
   "source": [
    "tokens = text3.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9e8992a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "40327874",
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 = \"Don't worry! We'll tokenize: correctly?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "188b9bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "46be1595",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_punct = punctuation.tokenize(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5896f0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Don', \"'\", 't', 'worry', '!', 'We', \"'\", 'll', 'tokenize', ':', 'correctly', '?']\n"
     ]
    }
   ],
   "source": [
    "print(tokenize_punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d29fada",
   "metadata": {},
   "source": [
    "##  4.Regex Tokenizer (only keep words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "597d6536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "081ce2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_expression = RegexpTokenizer(r'\\w+')\n",
    "#The regular expression pattern(r'\\w+'), \\w matches any word character: [a-zA-Z0-9_] (letters, digits, underscores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "64d63fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text5 = \"Tokenize only words! Exclude punctuation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f1103974",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokense2 = regular_expression.tokenize(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e8c1be77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tokenize', 'only', 'words', 'Exclude', 'punctuation']\n"
     ]
    }
   ],
   "source": [
    "print(tokense2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192f1004",
   "metadata": {},
   "source": [
    "## 5.Blankline Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f8406d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import blankline_tokenize\n",
    "# blankline = blankline_tokenize(token)\n",
    "# len(blankline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afdc704",
   "metadata": {},
   "source": [
    "##  N-grams: Unigram, Bigram, Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c8b56ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams, trigrams, bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "2a8c8927",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"Natural language processing (NLP) is a machine learning technology that gives computers the ability to interpret, manipulate, and comprehend human language. Organizations today have large volumes of voice and text data from various communication channels like emails, text messages, social media newsfeeds, video, audio, and more. They use NLP software to automatically process this data, analyze the intent or sentiment in the message, and respond in real time to human communication.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "fcc25a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'technology',\n",
       " 'that',\n",
       " 'gives',\n",
       " 'computers',\n",
       " 'the',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'interpret',\n",
       " ',',\n",
       " 'manipulate',\n",
       " ',',\n",
       " 'and',\n",
       " 'comprehend',\n",
       " 'human',\n",
       " 'language',\n",
       " '.',\n",
       " 'Organizations',\n",
       " 'today',\n",
       " 'have',\n",
       " 'large',\n",
       " 'volumes',\n",
       " 'of',\n",
       " 'voice',\n",
       " 'and',\n",
       " 'text',\n",
       " 'data',\n",
       " 'from',\n",
       " 'various',\n",
       " 'communication',\n",
       " 'channels',\n",
       " 'like',\n",
       " 'emails',\n",
       " ',',\n",
       " 'text',\n",
       " 'messages',\n",
       " ',',\n",
       " 'social',\n",
       " 'media',\n",
       " 'newsfeeds',\n",
       " ',',\n",
       " 'video',\n",
       " ',',\n",
       " 'audio',\n",
       " ',',\n",
       " 'and',\n",
       " 'more',\n",
       " '.',\n",
       " 'They',\n",
       " 'use',\n",
       " 'NLP',\n",
       " 'software',\n",
       " 'to',\n",
       " 'automatically',\n",
       " 'process',\n",
       " 'this',\n",
       " 'data',\n",
       " ',',\n",
       " 'analyze',\n",
       " 'the',\n",
       " 'intent',\n",
       " 'or',\n",
       " 'sentiment',\n",
       " 'in',\n",
       " 'the',\n",
       " 'message',\n",
       " ',',\n",
       " 'and',\n",
       " 'respond',\n",
       " 'in',\n",
       " 'real',\n",
       " 'time',\n",
       " 'to',\n",
       " 'human',\n",
       " 'communication',\n",
       " '.']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "woto = word_tokenize(string)\n",
    "woto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5f5883c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Natural', 'language'),\n",
       " ('language', 'processing'),\n",
       " ('processing', '('),\n",
       " ('(', 'NLP'),\n",
       " ('NLP', ')'),\n",
       " (')', 'is'),\n",
       " ('is', 'a'),\n",
       " ('a', 'machine'),\n",
       " ('machine', 'learning'),\n",
       " ('learning', 'technology'),\n",
       " ('technology', 'that'),\n",
       " ('that', 'gives'),\n",
       " ('gives', 'computers'),\n",
       " ('computers', 'the'),\n",
       " ('the', 'ability'),\n",
       " ('ability', 'to'),\n",
       " ('to', 'interpret'),\n",
       " ('interpret', ','),\n",
       " (',', 'manipulate'),\n",
       " ('manipulate', ','),\n",
       " (',', 'and'),\n",
       " ('and', 'comprehend'),\n",
       " ('comprehend', 'human'),\n",
       " ('human', 'language'),\n",
       " ('language', '.'),\n",
       " ('.', 'Organizations'),\n",
       " ('Organizations', 'today'),\n",
       " ('today', 'have'),\n",
       " ('have', 'large'),\n",
       " ('large', 'volumes'),\n",
       " ('volumes', 'of'),\n",
       " ('of', 'voice'),\n",
       " ('voice', 'and'),\n",
       " ('and', 'text'),\n",
       " ('text', 'data'),\n",
       " ('data', 'from'),\n",
       " ('from', 'various'),\n",
       " ('various', 'communication'),\n",
       " ('communication', 'channels'),\n",
       " ('channels', 'like'),\n",
       " ('like', 'emails'),\n",
       " ('emails', ','),\n",
       " (',', 'text'),\n",
       " ('text', 'messages'),\n",
       " ('messages', ','),\n",
       " (',', 'social'),\n",
       " ('social', 'media'),\n",
       " ('media', 'newsfeeds'),\n",
       " ('newsfeeds', ','),\n",
       " (',', 'video'),\n",
       " ('video', ','),\n",
       " (',', 'audio'),\n",
       " ('audio', ','),\n",
       " (',', 'and'),\n",
       " ('and', 'more'),\n",
       " ('more', '.'),\n",
       " ('.', 'They'),\n",
       " ('They', 'use'),\n",
       " ('use', 'NLP'),\n",
       " ('NLP', 'software'),\n",
       " ('software', 'to'),\n",
       " ('to', 'automatically'),\n",
       " ('automatically', 'process'),\n",
       " ('process', 'this'),\n",
       " ('this', 'data'),\n",
       " ('data', ','),\n",
       " (',', 'analyze'),\n",
       " ('analyze', 'the'),\n",
       " ('the', 'intent'),\n",
       " ('intent', 'or'),\n",
       " ('or', 'sentiment'),\n",
       " ('sentiment', 'in'),\n",
       " ('in', 'the'),\n",
       " ('the', 'message'),\n",
       " ('message', ','),\n",
       " (',', 'and'),\n",
       " ('and', 'respond'),\n",
       " ('respond', 'in'),\n",
       " ('in', 'real'),\n",
       " ('real', 'time'),\n",
       " ('time', 'to'),\n",
       " ('to', 'human'),\n",
       " ('human', 'communication'),\n",
       " ('communication', '.')]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = list(nltk.bigrams(woto))\n",
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "cec17af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Natural', 'language', 'processing'),\n",
       " ('language', 'processing', '('),\n",
       " ('processing', '(', 'NLP'),\n",
       " ('(', 'NLP', ')'),\n",
       " ('NLP', ')', 'is'),\n",
       " (')', 'is', 'a'),\n",
       " ('is', 'a', 'machine'),\n",
       " ('a', 'machine', 'learning'),\n",
       " ('machine', 'learning', 'technology'),\n",
       " ('learning', 'technology', 'that'),\n",
       " ('technology', 'that', 'gives'),\n",
       " ('that', 'gives', 'computers'),\n",
       " ('gives', 'computers', 'the'),\n",
       " ('computers', 'the', 'ability'),\n",
       " ('the', 'ability', 'to'),\n",
       " ('ability', 'to', 'interpret'),\n",
       " ('to', 'interpret', ','),\n",
       " ('interpret', ',', 'manipulate'),\n",
       " (',', 'manipulate', ','),\n",
       " ('manipulate', ',', 'and'),\n",
       " (',', 'and', 'comprehend'),\n",
       " ('and', 'comprehend', 'human'),\n",
       " ('comprehend', 'human', 'language'),\n",
       " ('human', 'language', '.'),\n",
       " ('language', '.', 'Organizations'),\n",
       " ('.', 'Organizations', 'today'),\n",
       " ('Organizations', 'today', 'have'),\n",
       " ('today', 'have', 'large'),\n",
       " ('have', 'large', 'volumes'),\n",
       " ('large', 'volumes', 'of'),\n",
       " ('volumes', 'of', 'voice'),\n",
       " ('of', 'voice', 'and'),\n",
       " ('voice', 'and', 'text'),\n",
       " ('and', 'text', 'data'),\n",
       " ('text', 'data', 'from'),\n",
       " ('data', 'from', 'various'),\n",
       " ('from', 'various', 'communication'),\n",
       " ('various', 'communication', 'channels'),\n",
       " ('communication', 'channels', 'like'),\n",
       " ('channels', 'like', 'emails'),\n",
       " ('like', 'emails', ','),\n",
       " ('emails', ',', 'text'),\n",
       " (',', 'text', 'messages'),\n",
       " ('text', 'messages', ','),\n",
       " ('messages', ',', 'social'),\n",
       " (',', 'social', 'media'),\n",
       " ('social', 'media', 'newsfeeds'),\n",
       " ('media', 'newsfeeds', ','),\n",
       " ('newsfeeds', ',', 'video'),\n",
       " (',', 'video', ','),\n",
       " ('video', ',', 'audio'),\n",
       " (',', 'audio', ','),\n",
       " ('audio', ',', 'and'),\n",
       " (',', 'and', 'more'),\n",
       " ('and', 'more', '.'),\n",
       " ('more', '.', 'They'),\n",
       " ('.', 'They', 'use'),\n",
       " ('They', 'use', 'NLP'),\n",
       " ('use', 'NLP', 'software'),\n",
       " ('NLP', 'software', 'to'),\n",
       " ('software', 'to', 'automatically'),\n",
       " ('to', 'automatically', 'process'),\n",
       " ('automatically', 'process', 'this'),\n",
       " ('process', 'this', 'data'),\n",
       " ('this', 'data', ','),\n",
       " ('data', ',', 'analyze'),\n",
       " (',', 'analyze', 'the'),\n",
       " ('analyze', 'the', 'intent'),\n",
       " ('the', 'intent', 'or'),\n",
       " ('intent', 'or', 'sentiment'),\n",
       " ('or', 'sentiment', 'in'),\n",
       " ('sentiment', 'in', 'the'),\n",
       " ('in', 'the', 'message'),\n",
       " ('the', 'message', ','),\n",
       " ('message', ',', 'and'),\n",
       " (',', 'and', 'respond'),\n",
       " ('and', 'respond', 'in'),\n",
       " ('respond', 'in', 'real'),\n",
       " ('in', 'real', 'time'),\n",
       " ('real', 'time', 'to'),\n",
       " ('time', 'to', 'human'),\n",
       " ('to', 'human', 'communication'),\n",
       " ('human', 'communication', '.')]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = list(nltk.trigrams(woto))\n",
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d7feb9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Natural', 'language', 'processing', '(', 'NLP'),\n",
       " ('language', 'processing', '(', 'NLP', ')'),\n",
       " ('processing', '(', 'NLP', ')', 'is'),\n",
       " ('(', 'NLP', ')', 'is', 'a'),\n",
       " ('NLP', ')', 'is', 'a', 'machine'),\n",
       " (')', 'is', 'a', 'machine', 'learning'),\n",
       " ('is', 'a', 'machine', 'learning', 'technology'),\n",
       " ('a', 'machine', 'learning', 'technology', 'that'),\n",
       " ('machine', 'learning', 'technology', 'that', 'gives'),\n",
       " ('learning', 'technology', 'that', 'gives', 'computers'),\n",
       " ('technology', 'that', 'gives', 'computers', 'the'),\n",
       " ('that', 'gives', 'computers', 'the', 'ability'),\n",
       " ('gives', 'computers', 'the', 'ability', 'to'),\n",
       " ('computers', 'the', 'ability', 'to', 'interpret'),\n",
       " ('the', 'ability', 'to', 'interpret', ','),\n",
       " ('ability', 'to', 'interpret', ',', 'manipulate'),\n",
       " ('to', 'interpret', ',', 'manipulate', ','),\n",
       " ('interpret', ',', 'manipulate', ',', 'and'),\n",
       " (',', 'manipulate', ',', 'and', 'comprehend'),\n",
       " ('manipulate', ',', 'and', 'comprehend', 'human'),\n",
       " (',', 'and', 'comprehend', 'human', 'language'),\n",
       " ('and', 'comprehend', 'human', 'language', '.'),\n",
       " ('comprehend', 'human', 'language', '.', 'Organizations'),\n",
       " ('human', 'language', '.', 'Organizations', 'today'),\n",
       " ('language', '.', 'Organizations', 'today', 'have'),\n",
       " ('.', 'Organizations', 'today', 'have', 'large'),\n",
       " ('Organizations', 'today', 'have', 'large', 'volumes'),\n",
       " ('today', 'have', 'large', 'volumes', 'of'),\n",
       " ('have', 'large', 'volumes', 'of', 'voice'),\n",
       " ('large', 'volumes', 'of', 'voice', 'and'),\n",
       " ('volumes', 'of', 'voice', 'and', 'text'),\n",
       " ('of', 'voice', 'and', 'text', 'data'),\n",
       " ('voice', 'and', 'text', 'data', 'from'),\n",
       " ('and', 'text', 'data', 'from', 'various'),\n",
       " ('text', 'data', 'from', 'various', 'communication'),\n",
       " ('data', 'from', 'various', 'communication', 'channels'),\n",
       " ('from', 'various', 'communication', 'channels', 'like'),\n",
       " ('various', 'communication', 'channels', 'like', 'emails'),\n",
       " ('communication', 'channels', 'like', 'emails', ','),\n",
       " ('channels', 'like', 'emails', ',', 'text'),\n",
       " ('like', 'emails', ',', 'text', 'messages'),\n",
       " ('emails', ',', 'text', 'messages', ','),\n",
       " (',', 'text', 'messages', ',', 'social'),\n",
       " ('text', 'messages', ',', 'social', 'media'),\n",
       " ('messages', ',', 'social', 'media', 'newsfeeds'),\n",
       " (',', 'social', 'media', 'newsfeeds', ','),\n",
       " ('social', 'media', 'newsfeeds', ',', 'video'),\n",
       " ('media', 'newsfeeds', ',', 'video', ','),\n",
       " ('newsfeeds', ',', 'video', ',', 'audio'),\n",
       " (',', 'video', ',', 'audio', ','),\n",
       " ('video', ',', 'audio', ',', 'and'),\n",
       " (',', 'audio', ',', 'and', 'more'),\n",
       " ('audio', ',', 'and', 'more', '.'),\n",
       " (',', 'and', 'more', '.', 'They'),\n",
       " ('and', 'more', '.', 'They', 'use'),\n",
       " ('more', '.', 'They', 'use', 'NLP'),\n",
       " ('.', 'They', 'use', 'NLP', 'software'),\n",
       " ('They', 'use', 'NLP', 'software', 'to'),\n",
       " ('use', 'NLP', 'software', 'to', 'automatically'),\n",
       " ('NLP', 'software', 'to', 'automatically', 'process'),\n",
       " ('software', 'to', 'automatically', 'process', 'this'),\n",
       " ('to', 'automatically', 'process', 'this', 'data'),\n",
       " ('automatically', 'process', 'this', 'data', ','),\n",
       " ('process', 'this', 'data', ',', 'analyze'),\n",
       " ('this', 'data', ',', 'analyze', 'the'),\n",
       " ('data', ',', 'analyze', 'the', 'intent'),\n",
       " (',', 'analyze', 'the', 'intent', 'or'),\n",
       " ('analyze', 'the', 'intent', 'or', 'sentiment'),\n",
       " ('the', 'intent', 'or', 'sentiment', 'in'),\n",
       " ('intent', 'or', 'sentiment', 'in', 'the'),\n",
       " ('or', 'sentiment', 'in', 'the', 'message'),\n",
       " ('sentiment', 'in', 'the', 'message', ','),\n",
       " ('in', 'the', 'message', ',', 'and'),\n",
       " ('the', 'message', ',', 'and', 'respond'),\n",
       " ('message', ',', 'and', 'respond', 'in'),\n",
       " (',', 'and', 'respond', 'in', 'real'),\n",
       " ('and', 'respond', 'in', 'real', 'time'),\n",
       " ('respond', 'in', 'real', 'time', 'to'),\n",
       " ('in', 'real', 'time', 'to', 'human'),\n",
       " ('real', 'time', 'to', 'human', 'communication'),\n",
       " ('time', 'to', 'human', 'communication', '.')]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = list(nltk.ngrams(woto,5))\n",
    "bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52efe59",
   "metadata": {},
   "source": [
    "## Stemming: Normalized words into its based from or root form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "49add5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "pst = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e3b07f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'affect'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem('affective')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ca8c065e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giving:give\n",
      "achivement:achiv\n",
      "impressive:impress\n",
      "implementing:implement\n",
      "Blocking:block\n",
      "Engineering:engin\n"
     ]
    }
   ],
   "source": [
    "word_to_stem=['giving','achivement','impressive','implementing','Blocking','Engineering']\n",
    "for words in word_to_stem:\n",
    "    print(words+ \":\" +pst.stem(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c03ca368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giving:giv\n",
      "achivement:ach\n",
      "impressive:impress\n",
      "implementing:impl\n",
      "Blocking:block\n",
      "Engineering:engin\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "pst = LancasterStemmer()\n",
    "for words in word_to_stem:\n",
    "    print(words+ \":\" +pst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "37e34824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giving:give\n",
      "achivement:achiv\n",
      "impressive:impress\n",
      "implementing:implement\n",
      "Blocking:block\n",
      "Engineering:engin\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "pst = SnowballStemmer('english')\n",
    "for words in word_to_stem:\n",
    "    print(words+ \":\" +pst.stem(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039addb0",
   "metadata": {},
   "source": [
    "## Lemmatization: Lemmatization is the process of reducing a word to its dictionary form (lemma), lemmatization always returns real words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2f3c88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wo_lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4dccfef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpus'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wo_lem.lemmatize('corpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d0a2470a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giving:giving\n",
      "achivement:achivement\n",
      "impressive:impressive\n",
      "implementing:implementing\n",
      "Blocking:Blocking\n",
      "Engineering:Engineering\n"
     ]
    }
   ],
   "source": [
    "for words in word_to_stem:\n",
    "    print(words+ \":\" +wo_lem.lemmatize(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e02d5be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "61cc9ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 9), ('and', 4), ('nlp', 3), ('the', 3), ('to', 3)]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_top5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c11758",
   "metadata": {},
   "source": [
    "## Parts of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e3a5893e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('There', 'EX')]\n",
      "[('is', 'VBZ')]\n",
      "[('chance', 'NN')]\n",
      "[('get', 'VB')]\n",
      "[('a', 'DT')]\n",
      "[('Bike', 'IN')]\n",
      "[('from', 'IN')]\n",
      "[('your', 'PRP$')]\n",
      "[('mom', 'NN')]\n",
      "[('!', '.')]\n",
      "[('John', 'NNP')]\n",
      "[('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"There is chance get a Bike from your mom! John.\"\n",
    "sentence_token = word_tokenize(sentence)\n",
    "for token in sentence_token:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "bf9c97d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('We', 'PRP')]\n",
      "[('are', 'VBP')]\n",
      "[('willing', 'JJ')]\n",
      "[('to', 'TO')]\n",
      "[('achive', 'JJ')]\n",
      "[('1000', 'CD')]\n",
      "[('ds', 'NN')]\n",
      "[('from', 'IN')]\n",
      "[('first', 'RB')]\n",
      "[('job', 'NN')]\n",
      "[('!', '.')]\n",
      "[('what', 'WP')]\n",
      "[('do', 'VB')]\n",
      "[('you', 'PRP')]\n",
      "[('think', 'NN')]\n",
      "[('Masud', 'NN')]\n",
      "[('?', '.')]\n"
     ]
    }
   ],
   "source": [
    "sentence2 = \"We are willing to achive 1000 ds from first job! what do you think Masud?\"\n",
    "sent_token2 = word_tokenize(sentence2)\n",
    "for token in sent_token2:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96181ae7",
   "metadata": {},
   "source": [
    "## NER: Name entity recogtition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "913b0a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a025e21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('US', 'NNP'), ('president', 'NN'), ('stays', 'NNS'), ('in', 'IN'), ('White', 'NNP'), ('House', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "ne_sent = \"US president stays in White House.\"\n",
    "ne_tokens = word_tokenize(ne_sent)\n",
    "ne_tags = nltk.pos_tag(ne_tokens)\n",
    "print(ne_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "788ff430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER = ne_chunk(ne_tags)\n",
    "# print(NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8c0281",
   "metadata": {},
   "source": [
    "## Regular Expression\n",
    "***re.findall()*** | Find all matches of a pattern in a text | re.findall(r'\\d+', text)\n",
    "***re.search()*** | Search for the first match | re.search(r'pattern', text)\n",
    "***re.match()*** | Check if the beginning of the text matches | re.match(r'Hello', text)\n",
    "***re.split()*** | Split text by a regex pattern | re.split(r'[,\\s]', text)\n",
    "***re.sub()*** | Substitute (replace) matches with something else | re.sub(r'apple', 'banana', text)\n",
    "***re.compile()*** | Compile a regex pattern for reuse | pattern = re.compile(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d26466cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 5), match='Masud'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "string = \"Masud is working hard to learn AI also he is seeking to learn theories from reading books.\"\n",
    "pattern = 'Masud'\n",
    "match = re.match(pattern, string)\n",
    "print(match)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9963826c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(25, 30), match='learn'>\n",
      "learn\n"
     ]
    }
   ],
   "source": [
    "pattern2 = \"learn\"\n",
    "search = re.search(pattern2,string)\n",
    "print(search)\n",
    "print(search.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f6301c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['learn', 'learn']\n"
     ]
    }
   ],
   "source": [
    "pattern3 = \"learn\"\n",
    "all = re.findall(pattern2 , string)\n",
    "print(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "8bc5afbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "index = re.finditer(pattern, string)\n",
    "for indx in index:\n",
    "    print(indx.start())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18311b4a",
   "metadata": {},
   "source": [
    "#### \\d{2}: Matches exactly two digits (e.g., \"12\").\n",
    "#### The pattern \\d{2}-\\d{2}-\\d{4} matches dates like \"12-05-2007\".\n",
    "#### \\s: Matches any whitespace (space, tab, etc.).\n",
    "#### So the pattern [;,\\s] splits the text whenever it sees a space, comma, or semicolon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8154fb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['16-12-2001', '22-07-2022']\n"
     ]
    }
   ],
   "source": [
    "text = \"Masud born in 16-12-2001 in Khulna, he admitted in University on 22-07-2022.\"\n",
    "pattern = r'\\d{2}-\\d{2}-\\d{4}'\n",
    "date = re.findall(pattern, text)\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "85fa9053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masud born in Sunday in Khulna, he admitted in University on Sunday.\n"
     ]
    }
   ],
   "source": [
    "print(re.sub(pattern, \"Sunday\", text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36105426",
   "metadata": {},
   "source": [
    "## Removing StopWords: \n",
    "### Words like ***“is”, “the”, “and”*** often add little meaning and should be filtered out.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "9fb2606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "5a7a2c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "3720e4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " 'is',\n",
       " 'a',\n",
       " 'fascinating',\n",
       " 'field',\n",
       " 'in',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " '.']"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Natural Language Processing is a fascinating field in Artificial Intelligence.\"\n",
    "token = nltk.word_tokenize(text)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "167a1329",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "88a66171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', 'fun', '&', 'interesting', 'part', 'computer', 'science', 'Artificial', 'Inteligence']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a941186c",
   "metadata": {},
   "source": [
    "## Remove punctuation from a text\n",
    "### ***string.punctuation*** : (!\"#$%&'()*+,-./:;<=>?@[\\]^_{|}~`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e2f0a241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "d96bfead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', '!', 'How', \"'s\", 'everything', 'going', 'in', '2025', '?', 'Let', \"'s\", 'test', 'punctuation', 'removal', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello! How's everything going in 2025? Let's test punctuation removal.\"\n",
    "token = nltk.word_tokenize(text)\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "672dd740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', 'is', 'fun', 'interesting', 'part', 'in', 'computer', 'science', 'and', 'Artificial', 'Inteligence']\n"
     ]
    }
   ],
   "source": [
    "tokens_no_punct = [word for word in tokens if word not in string.punctuation]\n",
    "print(tokens_no_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6679d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
